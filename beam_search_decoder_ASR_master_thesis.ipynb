{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDttqNRmz5EH",
        "outputId": "2c4ada6a-d51f-48ba-ccb8-d025294e7bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.33.4-py3-none-any.whl (534 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m534.7/534.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.3.3)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet_ml)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.27.1)\n",
            "Collecting semantic-version>=2.8.0 (from comet_ml)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet_ml)\n",
            "  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson (from comet_ml)\n",
            "  Downloading simplejson-3.19.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n",
            "Collecting websocket-client<1.4.0,>=0.55.0 (from comet_ml)\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.14.1)\n",
            "Collecting wurlitzer>=1.0.2 (from comet_ml)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.1/510.1 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.3.4)\n",
            "Collecting urllib3>2.0.0 (from comet_ml)\n",
            "  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.19.3)\n",
            "INFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting requests>=2.18.4 (from comet_ml)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2022.12.7)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Installing collected packages: everett, wurlitzer, websocket-client, urllib3, simplejson, semantic-version, python-box, configobj, sentry-sdk, requests, dulwich, requests-toolbelt, comet_ml\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.5.1\n",
            "    Uninstalling websocket-client-1.5.1:\n",
            "      Successfully uninstalled websocket-client-1.5.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comet_ml-3.33.4 configobj-5.0.8 dulwich-0.21.5 everett-3.1.0 python-box-6.1.0 requests-2.31.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-1.25.1 simplejson-3.19.1 urllib3-2.0.3 websocket-client-1.3.3 wurlitzer-3.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTy6RVBsU8-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d9540e-0833-46b1-8077-9521e76b6a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/models/decoder/_ctc_decoder.py:62: UserWarning: The built-in flashlight integration is deprecated, and will be removed in future release. Please install flashlight-text. https://pypi.org/project/flashlight-text/ For the detail of CTC decoder migration, please see https://github.com/pytorch/audio/issues/3088.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import os\n",
        "from typing import Tuple, Union\n",
        "from pathlib import Path\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio.models.decoder import ctc_decoder\n",
        "from torchaudio.utils import download_asset\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "import torch.utils.data as data\n",
        "\n",
        "import os\n",
        "from comet_ml import Experiment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQWML5zLXu5E"
      },
      "source": [
        "Прикрепляемся к нашему гугл диску, где в корне лежит AudioDiploma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmCUqEQ9L4hB",
        "outputId": "ef261705-696a-46e5-d68d-9298cee8a872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qw8Gjx0X4Nw"
      },
      "source": [
        "## Data clening and audio file path allocation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get csv from google drive, rename columns, and remove unused columns"
      ],
      "metadata": {
        "id": "UEr9xelX-ZXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbLOqsFlUtIw"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/AudioDiploma/swiss.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "\n",
        "path_bern = '/content/drive/MyDrive/AudioDiploma/clear_bern_test.csv'\n",
        "df_bern = pd.read_csv(path_bern)\n",
        "\n",
        "df_bern = df_bern.rename(columns={'path': 'filename', 'swiss translation': 'text'})\n",
        "df_bern = df_bern.drop(['sentence'], axis=1)\n",
        "\n",
        "\n",
        "path_bern_train = '/content/drive/MyDrive/AudioDiploma/clear_bern_train36.csv'\n",
        "df_bern_train = pd.read_csv(path_bern_train)\n",
        "\n",
        "df_bern_train = df_bern_train.rename(columns={'path': 'filename', 'swiss': 'text'})\n",
        "df_bern_train = df_bern_train.drop(['sentence'], axis=1)\n",
        "\n",
        "df_s = [df, df_bern, df_bern_train]\n",
        "df.shape[0], df_bern.shape[0], df_bern_train.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QduNIOR1YAkd"
      },
      "source": [
        "Прописываем пути напротив текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVXuBpGDVDFB"
      },
      "outputs": [],
      "source": [
        "def get_path(x):\n",
        "  '''allocation of corresponding audiofile path'''\n",
        "  tmp_mark = ''\n",
        "\n",
        "  if '1235' in x:\n",
        "    tmp_mark = '1235'\n",
        "  elif '1240' in x:\n",
        "    tmp_mark = '1240'\n",
        "  elif '.flac' in x:\n",
        "    tmp_mark = 'corpus2test'\n",
        "\n",
        "  default_path = '/content/drive/MyDrive/AudioDiploma/'\n",
        "  mark = (str(tmp_mark) + '/') if tmp_mark != '' else ''\n",
        "\n",
        "  return default_path + mark + x\n",
        "\n",
        "\n",
        "def get_path_big(x):\n",
        "  tmp_mark = 'clips'\n",
        "\n",
        "  default_path = '/content/drive/MyDrive/AudioDiploma/'\n",
        "  mark = (str(tmp_mark) + '/') if tmp_mark != '' else ''\n",
        "\n",
        "  return default_path + mark + x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove punctuation and add file path"
      ],
      "metadata": {
        "id": "nJ_LTdTB-yZ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaPnEQSLyNcN"
      },
      "outputs": [],
      "source": [
        "df['text'] = df['text'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "df_bern['text'] = df_bern['text'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "df_bern_train['text'] = df_bern_train['text'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "\n",
        "df['path'] = df.filename.apply(get_path)\n",
        "df_bern['path'] = df_bern.filename.apply(get_path)\n",
        "df_bern_train['path'] = df_bern_train.filename.apply(get_path_big)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "concat all dfs into one"
      ],
      "metadata": {
        "id": "DG7JTp3T_AqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8Uxab3fduGC"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(df_s)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df[34000:]\n",
        "len(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_5uQ49Cl_o7",
        "outputId": "c20e134b-abc2-4514-a528-a553439e466a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4586"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creation of helper files for Swiss Language model"
      ],
      "metadata": {
        "id": "wmQMPRLb_SXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract all words from swiss text to a vocabulary set\n",
        "nltk.download('punkt')\n",
        "vocab = set()\n",
        "for line in df.text:\n",
        "    tokens = word_tokenize(line)\n",
        "    words = [word.lower() for word in tokens if word.isalpha()]\n",
        "    vocab = vocab.union(set(words))\n",
        "vocab = sorted(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT-qixcGxyYV",
        "outputId": "26574b40-7073-4270-aad2-a3758d577a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[10505:10510]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnaDVtLE8f7y",
        "outputId": "1982a72f-7a16-43ea-e4a2-962c0aeeca02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ex', 'exakt', 'exakte', 'exakti', 'exampu']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add to lexicon file in format: \"word w o r d\\n\" for each line\n",
        "with open('lexicon.txt', 'w') as f:\n",
        "    for word in vocab:\n",
        "        f.write(word)\n",
        "        f.write(' ')\n",
        "        for letter in word:\n",
        "            f.write(letter)\n",
        "            f.write(' ')\n",
        "        #f.write('|')\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "SYyLVNhdzW7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of tokens\n",
        "tokens = ['', '|', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-']"
      ],
      "metadata": {
        "id": "BFDnITMF5wYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA4IcJIqxb0J"
      },
      "source": [
        "#Text similarity metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9ahI0GKe1vz"
      },
      "outputs": [],
      "source": [
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al34Syb-xz7A"
      },
      "source": [
        "# Audio preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyZoMPclxzGL",
        "outputId": "c461d838-d807-4711-bfef-6bc4dcd1f3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# return Mel Spectrograms after SpecAugment\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    '''Function transforms waveforms into spectrograms and\n",
        "    returns a list of spectrograms,\n",
        "              list of corresponding labels\n",
        "              list of input_lengths\n",
        "              list of label_lengths\n",
        "    '''\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85Ou2J6Lzoou"
      },
      "source": [
        "## Customized librispeech dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oNXdFK2zn1Q"
      },
      "outputs": [],
      "source": [
        "def load_librispeech_item_custom(item) -> Tuple[Tensor, int, str, int, int, int]:\n",
        "  '''class returns waveforms loaded from audio file'''\n",
        "  #Load audio\n",
        "  waveform, sample_rate = torchaudio.load(item.path)\n",
        "  transcript = item.text\n",
        "\n",
        "  return (\n",
        "        waveform,\n",
        "        0,\n",
        "        transcript,\n",
        "        0,\n",
        "        0,\n",
        "        0,)\n",
        "\n",
        "class LIBRISPEECH_CUSTOM(Dataset):\n",
        "\n",
        "    def __init__(self, df) -> None:\n",
        "        self._df = df\n",
        "\n",
        "    def __getitem__(self, n: int) -> Tuple[Tensor, int, str, int, int, int]:\n",
        "        \"\"\"Load the n-th sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample to be loaded\n",
        "\n",
        "        Returns:\n",
        "            (Tensor, int, str, int, int, int):\n",
        "            ``(waveform, sample_rate, transcript, speaker_id, chapter_id, utterance_id)``\n",
        "        \"\"\"\n",
        "        fileid = df.iloc[n]\n",
        "        return load_librispeech_item_custom(fileid)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._df.shape[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model and decoders"
      ],
      "metadata": {
        "id": "5WUpspBuBB7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Greedy decoder"
      ],
      "metadata": {
        "id": "ibpXuGg9A7Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "  '''function decodes characters from a given probability tensors one by one'''\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets"
      ],
      "metadata": {
        "id": "YoO5BT0tA9jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DNN architecture"
      ],
      "metadata": {
        "id": "kbzTO4qm_2ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjfbcsFxwYOm"
      },
      "outputs": [],
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "    '''Class implements bidirectional RNN with the GRU cell'''\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    '''class comprises residual CNNs, biRNNs and returns probability tensors'''\n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam decoder"
      ],
      "metadata": {
        "id": "q9P3axZ-_8AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LM_WEIGHT = 3.23\n",
        "WORD_SCORE = -0.26\n",
        "def Beam_Decoder(output):\n",
        "    '''beam search decoder implementation with swiss language model\n",
        "      returns a decoded string'''\n",
        "    beam_search_decoder = ctc_decoder(\n",
        "        lexicon='lexicon-2.txt',\n",
        "        tokens=tokens,\n",
        "        lm='/content/drive/MyDrive/AudioDiploma/LM/swiss_kenlm.bin',\n",
        "        #lm=None,\n",
        "        nbest=3,\n",
        "        beam_size=1500,\n",
        "        lm_weight=LM_WEIGHT,\n",
        "        word_score=WORD_SCORE,\n",
        "    )\n",
        "    beam_search_result = beam_search_decoder(output)\n",
        "    beam_search_transcript = \" \".join(beam_search_result[0][0].words).strip()\n",
        "    return beam_search_transcript"
      ],
      "metadata": {
        "id": "LjLIg7qVQxef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "Sc0rG_2j__1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIPPxECHwfBD"
      },
      "outputs": [],
      "source": [
        "def sample_test(model, test_loader):\n",
        "    '''function returns targets, greedy predictions and beam decoder predictions'''\n",
        "    model.eval()\n",
        "    #w = 0\n",
        "    #c = 0\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data\n",
        "            spectrograms, labels = spectrograms, labels\n",
        "\n",
        "#             print(spectrograms.size(), labels.size())\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            beam_decoded_preds = Beam_Decoder(output)\n",
        "            # emission = output?\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            #w += wer(decoded_targets[0], beam_decoded_preds)\n",
        "            #c += cer(decoded_targets[0], beam_decoded_preds)\n",
        "            #return beam_decoded_preds, decoded_preds[0], decoded_targets[0]\n",
        "            print('| ---------------------- Result ----------------- |')\n",
        "            print( 'target: ', decoded_targets[0], '\\n', 'decoded wombat: ', decoded_preds[0], '\\n', 'decoded beam: ', beam_decoded_preds, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN0QC5etd0Cx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDNN_WARN_NON_CONTIGUOUS'] = '0'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model upload from file.pth"
      ],
      "metadata": {
        "id": "RT7i1rF0AE61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma5-B5LAJbId"
      },
      "outputs": [],
      "source": [
        "def model_upload(path, learning_rate=5e-4, batch_size=1, epochs=15,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
        "    global data\n",
        "    #train_dataset = LIBRISPEECH_CUSTOM(train_df)\n",
        "    #test_dataset = LIBRISPEECH_CUSTOM(test_df)\n",
        "\n",
        "    hparams = {\n",
        "          \"n_cnn_layers\": 3,\n",
        "          \"n_rnn_layers\": 5,\n",
        "          \"rnn_dim\": 512,\n",
        "          \"n_class\": 29,\n",
        "          \"n_feats\": 128,\n",
        "          \"stride\":2,\n",
        "          \"dropout\": 0.1,\n",
        "          \"learning_rate\": learning_rate,\n",
        "          \"batch_size\": batch_size,\n",
        "          \"epochs\": epochs\n",
        "      }\n",
        "\n",
        "    torch.manual_seed(7)\n",
        "\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        )\n",
        "\n",
        "    # model = nn.DataParallel(model, device_ids=[0])\n",
        "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
        "\n",
        "    return model\n",
        "\n",
        "PATH = '/content/drive/MyDrive/AudioDiploma/train-models/model_v2.pth'\n",
        "model = model_upload(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Function for telegram decoding"
      ],
      "metadata": {
        "id": "oPFJUafhAIbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_telegram_message(audio_path_name):\n",
        "\n",
        "    d = {'filename': ['name'], 'text':['something was said'], 'path':[audio_path_name]}\n",
        "    df_unit = pd.DataFrame(data=d)\n",
        "\n",
        "    sample_dataset = LIBRISPEECH_CUSTOM(df_unit)\n",
        "\n",
        "    sample_loader = data.DataLoader(dataset=sample_dataset,\n",
        "                                    batch_size=1,\n",
        "                                    collate_fn=lambda x: data_processing(x, 'valid'))\n",
        "\n",
        "    model.eval()\n",
        "    return sample_test(model, sample_loader)\n",
        "\n",
        "res = decode_telegram_message('34432.flac')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGetcxdmTVyK",
        "outputId": "06536d54-7708-413f-c4ab-62b2b00a0ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ---------------------- Result ----------------- |\n",
            "target:  dr kanton het im bildigsbereich massnahme troffe drmit persone mit schlechte duetschkenntnis d grundkompetenze choei erreiche \n",
            " decoded wombat:  d kanto he im bildigsbereich massnahme detroffe dami persone mit schlechteduetsketnisu d grundkompetaenze erreichee \n",
            " decoded beam:  dr kanton het im bildigsbereich massnahme troffe drmit persone mit schlechte duetschkenntnis d grundkompetenze erreiche \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for inference for testing test dataset"
      ],
      "metadata": {
        "id": "Bj7WMBfFANBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_wer(test_df):\n",
        "    df_unit = pd.DataFrame(data=test_df)\n",
        "\n",
        "    sample_dataset = LIBRISPEECH_CUSTOM(df_unit)\n",
        "\n",
        "    sample_loader = data.DataLoader(dataset=sample_dataset,\n",
        "                                    batch_size=1,\n",
        "                                    collate_fn=lambda x: data_processing(x, 'valid'))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    sample_test(model, sample_loader)"
      ],
      "metadata": {
        "id": "QZrk8JCzo3br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = df.sample(20)\n",
        "test_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XA_XGQq93W5b",
        "outputId": "cb8ef87d-5d1c-4a80-c003-0e3ae557911e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index    filename                                               text  \\\n",
              "16880  33973  27358.flac  er cha so sicherstelle dass e aschlussvertrag ...   \n",
              "10475  14568  36490.flac  di mueglechkeit hei juristischi persone nid wi...   \n",
              "9550   32207  37447.flac  mir isch kes angers baernerischs ungernaehme i...   \n",
              "34742   3531  12663.flac  die schaede a gebaeude infrastruktur und kultu...   \n",
              "37949   4913   8714.flac  aber mir muend ufpasse dass nid der unternehme...   \n",
              "\n",
              "                                                    path  \n",
              "16880  /content/drive/MyDrive/AudioDiploma/clips/2735...  \n",
              "10475  /content/drive/MyDrive/AudioDiploma/clips/3649...  \n",
              "9550   /content/drive/MyDrive/AudioDiploma/clips/3744...  \n",
              "34742  /content/drive/MyDrive/AudioDiploma/clips/1266...  \n",
              "37949  /content/drive/MyDrive/AudioDiploma/clips/8714...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cbb35d3-54ed-486a-a762-5bebc019e7df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16880</th>\n",
              "      <td>33973</td>\n",
              "      <td>27358.flac</td>\n",
              "      <td>er cha so sicherstelle dass e aschlussvertrag ...</td>\n",
              "      <td>/content/drive/MyDrive/AudioDiploma/clips/2735...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10475</th>\n",
              "      <td>14568</td>\n",
              "      <td>36490.flac</td>\n",
              "      <td>di mueglechkeit hei juristischi persone nid wi...</td>\n",
              "      <td>/content/drive/MyDrive/AudioDiploma/clips/3649...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9550</th>\n",
              "      <td>32207</td>\n",
              "      <td>37447.flac</td>\n",
              "      <td>mir isch kes angers baernerischs ungernaehme i...</td>\n",
              "      <td>/content/drive/MyDrive/AudioDiploma/clips/3744...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34742</th>\n",
              "      <td>3531</td>\n",
              "      <td>12663.flac</td>\n",
              "      <td>die schaede a gebaeude infrastruktur und kultu...</td>\n",
              "      <td>/content/drive/MyDrive/AudioDiploma/clips/1266...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37949</th>\n",
              "      <td>4913</td>\n",
              "      <td>8714.flac</td>\n",
              "      <td>aber mir muend ufpasse dass nid der unternehme...</td>\n",
              "      <td>/content/drive/MyDrive/AudioDiploma/clips/8714...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cbb35d3-54ed-486a-a762-5bebc019e7df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cbb35d3-54ed-486a-a762-5bebc019e7df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cbb35d3-54ed-486a-a762-5bebc019e7df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_wer(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kQWeXcVD3QE",
        "outputId": "4b568679-c3f3-4c79-b20b-a3c2e3ebebcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ---------------------- Result ----------------- |\n",
            "target:  dr kanton het im bildigsbereich massnahme troffe drmit persone mit schlechte duetschkenntnis d grundkompetenze choei erreiche \n",
            " decoded wombat:  d kanto he im bildigsbereich massnahme detroffe dami persone mit schlechteduetsketnisu d grundkompetaenze erreichee \n",
            " decoded beam:  dr kanton het im bildigsbereich massnahme troffe drmit persone mit schlechte duetschkenntnis d grundkompetenze erreiche \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  es geit um ds potentiau fuer stromproduktion us wasserchraft fuer rund sechstausend hushaute \n",
            " decoded wombat:  es geit um ds potenzial fuer stromproduktion uswasserchraft fuerrund sechstausend hushaltige \n",
            " decoded beam:  es geit um ds potentiau fuer stromproduktion us wasserchraft fuer rund sechstausend hushaute \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  mir stelle ues dere diskussion und werde vorschlaeg praesentiere aber no nid huet \n",
            " decoded wombat:  ie ues re diskussion e waerde vorschle praesentiere e noniues \n",
            " decoded beam:  d diskussion werde vorschlaeg praesentiere \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  bi de vorlaeufig ufgnoh fluechtlinge wird sech de kanton starch a de sozialhilfechoeschte muesse beteilige \n",
            " decoded wombat:   bi de vorlaegig ufgnole fluechtlinge wird sech dr kanton starck ade sozialhilfechoschte muessebeteilige \n",
            " decoded beam:  bi de vorlaeufig ufgnoh fluechtlinge wird sech de kanton starch a de sozialhilfechoeschte muesse beteilige \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  ir praxis steue mir i de letschte jahr e strengeri handhabig vo de stueuerbehoerde fuer erlassgsuech faescht \n",
            " decoded wombat:  i praxisstele wir i de letschte jahre e strengeri handhabigo der stueuerbee fuer erlasgsuech \n",
            " decoded beam:  ir praxis steue mir i de letschte jahr e strengeri handhabig vo de stueuere fuer erlassgsuech \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  si si ja immer dr meinig dass sozialhilf el subsidiaer seg i zwoeiter linie \n",
            " decoded wombat:  mir sit immer dr meinig das sozialhilf  sbsidjaerisch i zweiterli \n",
            " decoded beam:  mir si dr meinig dass sozialhilf isch \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  d polizei wo das de letschtlich tue muess da cha de regierigsrat no so viel absichtserklaerige abgaeh die isch froh drum \n",
            " decoded wombat:   polie o das de letsec mues mah  isha dr regierigsrat no so absichtzerklaerige abgaeisch fr \n",
            " decoded beam:  dr regierigsrat absichtserklaerige abgaeh \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  abstimme werde mir selbstverstaendlich immer ueber di einzelne artikel \n",
            " decoded wombat:  mir stimme merselbstverstaendlech immer ueber di einzelne artike \n",
            " decoded beam:  mir stimme mir selbstverstaendlich immer ueber di einzelne artikel \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  das waer us uesere sicht e wichtige u noetige biitrag zur vertrauensbildig vor bevoeukerig id politik i die seroesi arbeit vo de kommissione u es wird sech o zeige ob ou id chiesbranche \n",
            " decoded wombat:  das waer us ueserrsich  wichtiger u oetiger bitra ur vertrauesbildig dr bevoelkerig d politik ieeoesi arbeit vor kommissione u s wid sech ozige ob i kisbroch \n",
            " decoded beam:  das waer us uesere sicht e wichtige bitrag zur vertrauensbildig vor bevoeukerig id politik arbeit vor kommission isch \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  di si fuer ues sehr wertvoll \n",
            " decoded wombat:  isi fuer ues sehr waert \n",
            " decoded beam:  fuer ues sehr \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  drum empfiehlt ne e knapp mehrheit vor fdp fraktion wo uf die teilrevision nid iiztraete \n",
            " decoded wombat:  drum empfilt  knapi mehrheit vo d fdp fraktion nid itraette uf di teil revision \n",
            " decoded beam:  drum empfiehlt d mehrheit vo de fdp fraktion niditraette teilrevision \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  seb isch unbestritte u ds soeu oh so blibe \n",
            " decoded wombat:  das isch unbestritte u das soeu o so blibe \n",
            " decoded beam:  das isch unbestritte u ds soeu oh so blibe \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  die ungersuechig u die forschig gits ir toeifi wie si noetig waer damit me naer o choennt politisch schluess drus zieh nid \n",
            " decoded wombat:  deuchi gitsi re tuefiwisnoetig waerdemit m opolitisch coi schluess druszit forschig \n",
            " decoded beam:  di noetige politische schluess \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  di grueeni fraktion bittet se dene aatrag abzlehne \n",
            " decoded wombat:  d grueni fraktion bittet  daem aatrag abzlehne \n",
            " decoded beam:  di grueeni fraktion bittet se dae aatrag abzlehne \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  mir wette o d chance vom direktionswechseu zur klaerig vo de verschidene uftraeg u fraagsteuige nutze wo rund um die praemieverbilligunge scho erteilt worde si \n",
            " decoded wombat:  mir wei chance vom direktionswaechsel nut zu zurklaerig vo dee verschidenige uftraeg u fragestellige worund um praemi verbilligungescho erteilt worde si \n",
            " decoded beam:  d chance direktionswechseu zur klaerig vo de verschidene uftraeg fragestellige praemieverbilligunge worde \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  d bevoeukerig vom kanton baern het sicher o nid weniger aspruech u erwartige i bezug uf d sicherheit aus angeri moensche ir schwiz \n",
            " decoded wombat:   be volkerig vom kanton baern ed sicher ou nid weniger aspruech un erwartige un bezug ufd sicherheit as anderi moenschi er schwiz \n",
            " decoded beam:  d bevoeukerig vom kanton baern het sicher o nid weniger aspruech u erwartige i bezug uf d sicherheit aus angeri moensche ir schwiz \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  mir gloube nid dass ueses milizparlament i der lag waer gsi e fundierti diskussion z komplexe buechigs und buechhaltigsvorschrifte z fueehre \n",
            " decoded wombat:  ds uesches milizsparlament idrlagwaerig sie fundieti dir funtierti diskussion zu komplexe buechigsu buechhaltigsvorschrifte z fueehre \n",
            " decoded beam:  ueses milizparlament fundierti diskussion z komplexe buechigs und buechhaltigsvorschrifte z fueehre \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  mir bruche itz zielfueehrendi massnahme zur verbesserig vor situation vor langzitarbeitslose \n",
            " decoded wombat:  mir bruchiz zilfueehrendi massnahm zur verbesserig voer situation voe langzitarbeitslose \n",
            " decoded beam:  zielfueehrendi massnahme zur verbesserig vor situation vor langzitarbeitslose \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  we immer aui betone sogenannti frouearbeit sig sehr wichtig u me mueessi se aendlech meh anerkenne de gits aebe nume eine waeg u das isch meh lohn \n",
            " decoded wombat:  we imme alibeton ne dass ogenan  fraue abe sehr wichtig isch u das mese entlim mues i amekenn wo i be nuiwaeg u aisch meloh \n",
            " decoded beam:  we immer aui betone sogenannti frouearbeit sehr wichtig isch \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  si gseh ds unger aatrag regierigsrat ii \n",
            " decoded wombat:  i de bi aatrag regierigsrat zwei \n",
            " decoded beam:  dr atrag regierigsrat \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}