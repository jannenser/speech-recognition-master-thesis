{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by3cwJHzDcFz",
        "outputId": "653ca796-04e7-498a-bd10-af15db62b549"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eTy6RVBsU8-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed32d761-4465-4c4d-d7fe-6366545fe8f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/models/decoder/_ctc_decoder.py:62: UserWarning: The built-in flashlight integration is deprecated, and will be removed in future release. Please install flashlight-text. https://pypi.org/project/flashlight-text/ For the detail of CTC decoder migration, please see https://github.com/pytorch/audio/issues/3088.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import os\n",
        "from typing import Tuple, Union\n",
        "from pathlib import Path\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio.models.decoder import ctc_decoder\n",
        "from torchaudio.utils import download_asset\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "import torch.utils.data as data\n",
        "\n",
        "import os\n",
        "#from comet_ml import Experiment\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import nltk\n",
        "#from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning for German"
      ],
      "metadata": {
        "id": "F8FaxOl0CGEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ['', '|', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-']"
      ],
      "metadata": {
        "id": "BFDnITMF5wYk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhwHzCPgvgJG",
        "outputId": "839a72da-00f1-4080-edbb-90f1b2f6de86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path_bern = '/content/drive/MyDrive/AudioDiploma/clear_bern_test.csv'\n",
        "df_bern = pd.read_csv(path_bern)\n",
        "\n",
        "df_bern = df_bern.rename(columns={'path': 'filename', 'sentence': 'text'})\n",
        "df_bern = df_bern.drop(['swiss translation'], axis=1)\n",
        "\n",
        "\n",
        "path_bern_train = '/content/drive/MyDrive/AudioDiploma/clear_bern_train36.csv'\n",
        "df_bern_train = pd.read_csv(path_bern_train)\n",
        "\n",
        "df_bern_train = df_bern_train.rename(columns={'path': 'filename', 'sentence': 'text'})\n",
        "df_bern_train = df_bern_train.drop(['swiss'], axis=1)\n",
        "\n",
        "df_s = [df_bern, df_bern_train]\n",
        "df_bern.shape[0], df_bern_train.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puMi5UH2vp2Y",
        "outputId": "c8699784-95a2-405a-c7de-d28a0c9decfc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2014, 36572)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bern.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CIp4eZ3HSKSm",
        "outputId": "e1de6f54-8f3c-4173-9bc0-37d9e0db29b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     filename                                               text\n",
              "0  38347.flac  wir motionaere wurden zusammen mit anderen int...\n",
              "1  21183.flac  wir sind darauf an gewiesen, dass die wirtscha...\n",
              "2  34897.flac  diese haben wir aber noch nicht, und deswegen ...\n",
              "3   1858.flac  das pricing des stroms ist relativ klar, es is...\n",
              "4   1622.flac  zum schluss noch etwas zum thema umgang mit ve..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94409359-d238-43ee-86fa-902598a5b13a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38347.flac</td>\n",
              "      <td>wir motionaere wurden zusammen mit anderen int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21183.flac</td>\n",
              "      <td>wir sind darauf an gewiesen, dass die wirtscha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34897.flac</td>\n",
              "      <td>diese haben wir aber noch nicht, und deswegen ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1858.flac</td>\n",
              "      <td>das pricing des stroms ist relativ klar, es is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1622.flac</td>\n",
              "      <td>zum schluss noch etwas zum thema umgang mit ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94409359-d238-43ee-86fa-902598a5b13a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94409359-d238-43ee-86fa-902598a5b13a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94409359-d238-43ee-86fa-902598a5b13a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_path(x):\n",
        "  tmp_mark = ''\n",
        "\n",
        "  if '1235' in x:\n",
        "    tmp_mark = '1235'\n",
        "  elif '1240' in x:\n",
        "    tmp_mark = '1240'\n",
        "  elif '.flac' in x:\n",
        "    tmp_mark = 'corpus2test'\n",
        "\n",
        "  default_path = '/content/drive/MyDrive/AudioDiploma/'\n",
        "  mark = (str(tmp_mark) + '/') if tmp_mark != '' else ''\n",
        "\n",
        "  return default_path + mark + x\n",
        "\n",
        "\n",
        "def get_path_big(x):\n",
        "  tmp_mark = 'clips'\n",
        "\n",
        "  default_path = '/content/drive/MyDrive/AudioDiploma/'\n",
        "  mark = (str(tmp_mark) + '/') if tmp_mark != '' else ''\n",
        "\n",
        "  return default_path + mark + x"
      ],
      "metadata": {
        "id": "Hm_ss982v_hs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bern['text'] = df_bern['text'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "df_bern_train['text'] = df_bern_train['text'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "\n",
        "df_bern['path'] = df_bern.filename.apply(get_path)\n",
        "df_bern_train['path'] = df_bern_train.filename.apply(get_path_big)"
      ],
      "metadata": {
        "id": "e3HoxYkTwCl_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_bern, df_bern_train])\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzMsca3cwKh0",
        "outputId": "33130554-219b-4a7e-bad7-87658f7e23d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38586, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']"
      ],
      "metadata": {
        "id": "sGQ_Vl-VV0IE",
        "outputId": "b69bffe3-4390-4736-8fd6-5fa069cd6508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        eine weitere liberalisierung fuehrt zu einem p...\n",
              "1        wie es jetzt im leitsatz formuliert ist und im...\n",
              "2        bei der vierten wahl einer laienrichterin fran...\n",
              "3        in der region bern stehen bereits achtundzwanz...\n",
              "4        deshalb ist es mir ein ganz persoenliches anli...\n",
              "                               ...                        \n",
              "38581     sie ist eine engagierte weitsichtige politikerin\n",
              "38582                   es hat zu wenig fleisch am knochen\n",
              "38583    gerade im bereich kleidung und im nahrungsmitt...\n",
              "38584    in diesem sinn sind wir absolut dafuer das so ...\n",
              "38585                                 wir haben es gehoert\n",
              "Name: text, Length: 38586, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA4IcJIqxb0J"
      },
      "source": [
        "# Text similarity metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g9ahI0GKe1vz"
      },
      "outputs": [],
      "source": [
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al34Syb-xz7A"
      },
      "source": [
        "# Audio preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UyZoMPclxzGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe07330-69eb-45e0-ac6a-4626fcbeef9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85Ou2J6Lzoou"
      },
      "source": [
        "## Customized librispeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9oNXdFK2zn1Q"
      },
      "outputs": [],
      "source": [
        "def load_librispeech_item_custom(item) -> Tuple[Tensor, int, str, int, int, int]:\n",
        "\n",
        "  #Load audio\n",
        "  waveform, sample_rate = torchaudio.load(item.path)\n",
        "  transcript = item.text\n",
        "\n",
        "  return (\n",
        "        waveform,\n",
        "        0,\n",
        "        transcript,\n",
        "        0,\n",
        "        0,\n",
        "        0,)\n",
        "\n",
        "class LIBRISPEECH_CUSTOM(Dataset):\n",
        "\n",
        "    def __init__(self, df) -> None:\n",
        "        self._df = df\n",
        "\n",
        "    def __getitem__(self, n: int) -> Tuple[Tensor, int, str, int, int, int]:\n",
        "        \"\"\"Load the n-th sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample to be loaded\n",
        "\n",
        "        Returns:\n",
        "            (Tensor, int, str, int, int, int):\n",
        "            ``(waveform, sample_rate, transcript, speaker_id, chapter_id, utterance_id)``\n",
        "        \"\"\"\n",
        "        fileid = self._df.iloc[n]\n",
        "        return load_librispeech_item_custom(fileid)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._df.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gJoOEWkYeoHt"
      },
      "outputs": [],
      "source": [
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN architecture"
      ],
      "metadata": {
        "id": "qSpff8stB5vo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OjfbcsFxwYOm"
      },
      "outputs": [],
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "\n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "w7CVGb4qB-vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LM_WEIGHT = 1.23\n",
        "WORD_SCORE = -0.26\n",
        "def Beam_Decoder(output):\n",
        "    beam_search_decoder = ctc_decoder(\n",
        "        lexicon='/content/drive/MyDrive/AudioDiploma/LM/deu-lexicon.txt',\n",
        "        tokens=tokens,\n",
        "        lm='/content/drive/MyDrive/AudioDiploma/LM/de.arpa.bin',\n",
        "        nbest=3,\n",
        "        beam_size=1500,\n",
        "        lm_weight=LM_WEIGHT,\n",
        "        word_score=WORD_SCORE,\n",
        "    )\n",
        "    beam_search_result = beam_search_decoder(output)\n",
        "    beam_search_transcript = \" \".join(beam_search_result[0][0].words).strip()\n",
        "    return beam_search_transcript"
      ],
      "metadata": {
        "id": "LjLIg7qVQxef"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "KIPPxECHwfBD"
      },
      "outputs": [],
      "source": [
        "def sample_test(model, test_loader):\n",
        "    model.eval()\n",
        "    w = 0\n",
        "    c = 0\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data\n",
        "            spectrograms, labels = spectrograms, labels\n",
        "\n",
        "#             print(spectrograms.size(), labels.size())\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            beam_decoded_preds = Beam_Decoder(output)\n",
        "\n",
        "            # emission = output?\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            w += wer(decoded_targets[0], beam_decoded_preds)\n",
        "            c += cer(decoded_targets[0], beam_decoded_preds)\n",
        "            #return beam_decoded_preds, decoded_preds[0], decoded_targets[0]\n",
        "            print('| ---------------------- Result ----------------- |')\n",
        "            print( 'target: ', decoded_targets[0], '\\n', 'decoded wombat: ', decoded_preds[0], '\\n', 'decoded beam: ', beam_decoded_preds, '\\n')\n",
        "    return w, c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDNN_WARN_NON_CONTIGUOUS'] = '0'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "OHNzU3TwAC5K"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ma5-B5LAJbId"
      },
      "outputs": [],
      "source": [
        "def model_upload(path, learning_rate=5e-4, batch_size=1, epochs=15,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
        "    global data\n",
        "\n",
        "    hparams = {\n",
        "          \"n_cnn_layers\": 3,\n",
        "          \"n_rnn_layers\": 5,\n",
        "          \"rnn_dim\": 512,\n",
        "          \"n_class\": 29,\n",
        "          \"n_feats\": 128,\n",
        "          \"stride\":2,\n",
        "          \"dropout\": 0.1,\n",
        "          \"learning_rate\": learning_rate,\n",
        "          \"batch_size\": batch_size,\n",
        "          \"epochs\": epochs\n",
        "      }\n",
        "\n",
        "    torch.manual_seed(7)\n",
        "\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        )\n",
        "\n",
        "    model = nn.DataParallel(model, device_ids=[0])\n",
        "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
        "\n",
        "    return model\n",
        "\n",
        "PATH = '/content/drive/MyDrive/AudioDiploma/train-models/best_model_german.pth'\n",
        "model = model_upload(PATH)\n",
        "model = model.module.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_telegram_message(audio_path_name):\n",
        "\n",
        "    d = {'filename': ['name'], 'text':['something was said'], 'path':[audio_path_name]}\n",
        "    df_unit = pd.DataFrame(data=d)\n",
        "\n",
        "    sample_dataset = LIBRISPEECH_CUSTOM(df_unit)\n",
        "\n",
        "    sample_loader = data.DataLoader(dataset=sample_dataset,\n",
        "                                    batch_size=1,\n",
        "                                    collate_fn=lambda x: data_processing(x, 'valid'))\n",
        "\n",
        "    #model.eval()\n",
        "    return sample_test(model, sample_loader)\n",
        "\n",
        "#print(decode_telegram_message('13830.flac'))"
      ],
      "metadata": {
        "id": "PGetcxdmTVyK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.sample(20)"
      ],
      "metadata": {
        "id": "-r8BGtWP8kp5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wrBENTIWVYE",
        "outputId": "948ddef3-dab6-47cd-c6d3-fee4546e947d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 18 16:32:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    31W /  70W |    701MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_wer_cer(df_unit):\n",
        "    sample_dataset = LIBRISPEECH_CUSTOM(df_unit)\n",
        "\n",
        "    sample_loader = data.DataLoader(dataset=sample_dataset,\n",
        "                                    batch_size=1,\n",
        "                                    collate_fn=lambda x: data_processing(x, 'valid'))\n",
        "\n",
        "    model.eval()\n",
        "    return sample_test(model, sample_loader)"
      ],
      "metadata": {
        "id": "QMVJ0dxk8vJ0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, c = avg_wer_cer(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0rzKe3w85SA",
        "outputId": "d9585bd3-a470-4df4-9228-94777f2cb921"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ---------------------- Result ----------------- |\n",
            "target:  wer den abaenderungsantrag sechs annehmen will stimmt ja wer dies nicht moechte stimmt nein \n",
            " decoded wombat:  wed aenderuns soehnn mt ja wer dmt nen \n",
            " decoded beam:  aenderung \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  aber wieso muss der kanton ebenfalls ein gleichstellungsbuero fuehren \n",
            " decoded wombat:  aber bieso muss der kanton ebenfals ei gleichstellungsbuerlofier \n",
            " decoded beam:  bis der kan ton al gleichstellungsbuero \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  die gruene fraktion wird ebenfalls die wahl von regierungsrat christoph neuhaus zum regierungsvizepraesidenten unterstuetzen und wuenscht auch ihm viel energie und freude bei der weiteren arbeit \n",
            " decoded wombat:  die gruene fraktion wir ebenfals diwahl des regierungsratchis of neu haus alsvizen unterstuetzen und wuensta iim vielwenergie und froeut bei der weiteren arbeit \n",
            " decoded beam:  diegruene fraktion wir ebenfalls wahl des regierungsrats neuhaus asien unterstuetzenden spiel energie und freut bei der weiteren arbeit \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  es ist ja klar dass die einfuehrung eines feiertags nicht die loesung fuer die lohngleichheit waere aber mit einem freien acht maerz koennte der kanton bern auch eine vorreiterrolle uebernehmen und eben zeigen dass uns lohngleichheit ein anliegen ist \n",
            " decoded wombat:  e miti frie hte  koenn i der kanton bern auce vorreterollen ieberhe und zeigebe dass longlichheit unsei e \n",
            " decoded beam:  treten der kan ton bern vorreiterrolle nieder und s eigenen das lang licht une \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  wo gearbeitet wird passieren fehler \n",
            " decoded wombat:   de geschaffet wird da gaschieren feh \n",
            " decoded beam:  geschaffen wird passieren f \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  zehntausend neue paedagogen jedes jahr schweizweit natuerlich \n",
            " decoded wombat:  dieausin neu peagogen jedes jahr schweizwinatuelich \n",
            " decoded beam:  neu go gen des jahr schweizweiter \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  es ist ein thema das praesent ist \n",
            " decoded wombat:  des ist e themun diplisentist  \n",
            " decoded beam:  ist themen eisen \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  dies ist voellig uebertrieben und unverhaeltnismaessig und dies sei zusaetzlich erwaehnt ohne gesetzliche grundlage \n",
            " decoded wombat:  das ist das voellig uebertrieben und umfraelismessig und de es nochmalserwaehnd ohne gesetzliche grundla \n",
            " decoded beam:  das ist voellig uebertrieben und um freie nochmals erwaehnt ohne gesetzliche grund \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  das ist nicht wenig geld dreisechs mrd franken in den naechsten dreissig jahren \n",
            " decoded wombat:  das ist nicht wenige dreisechs mi ade franken in der echendreissig jah \n",
            " decoded beam:  da ist nicht wenige dreisechs in der dreissig \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  deshalb muessen wir bei der abstimmung das ganze drehen und zuerst ueber den artikel vierundachtzig beschliessen \n",
            " decoded wombat:  dashal muessen wir beider abstimmung das ganzedren und zuerst der artikel vierundachtzig beschliesen do \n",
            " decoded beam:  deshalb muessen wir beider abstimmung das enden und zu der artikel vierundachtzig beschliessen \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  zwischen huttwil und langenthal liegen verschiedene groessere doerfer so madiswil rohrbach und lotzwil mit einer bevoelkerung die regelmaessig den oev benutzen will kann muss und darf \n",
            " decoded wombat:  deutwil und langentau git des verschiedenen groesseredoerfer ma die s ilrorbach undnohzwil und damit befoelkerung die regelmaessig denoefa benutzen wil ann mus und darf \n",
            " decoded beam:  wind lang en es verschiedenen groesserer sil or ach und ziel und mit bevoelkerung die regelmaessigen oev benutzen will mund \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  dieses kunstwerk haben wir hier vor uns \n",
            " decoded wombat:  du des konstwerk aben wir he vor uns ha \n",
            " decoded beam:  des kunstwerk bi vor us \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  genau fuer diese absicht sie nochmals zu hinterfragen ist das postulat die richtige loesung \n",
            " decoded wombat:  a uer dieefuer dieser fintefragen ist des postulat die richtigen loe \n",
            " decoded beam:  dieser hinterfragen des postulat die richtigen \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  einer der punkte wo ich grosses sparpotenzial orte liegt bei der risikobeurteilung \n",
            " decoded wombat:  de ganz grossen punkt die i sparpotenzialworten ist in derweisekobeorteiig \n",
            " decoded beam:  grossen punkt sparpotenzial orte in der weise berg \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  ja das haben wir in der motion auch gehabt \n",
            " decoded wombat:  j dass haben wir ki der motion es gibt ueber \n",
            " decoded beam:  das haben den motion gibt er \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  erstens ein bericht ist notwendig weil in den letzten zehn jahren ein enormer wandel stattgefunden hat \n",
            " decoded wombat:  detens ein bericht istt notwendig weil in den letzten zein jahrn ein ennormmerwandel stattgefund na \n",
            " decoded beam:  ein bericht ist notwendig weil in den letzte n en jahr en enormer wandel stattgefunden \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  aber damit wird ein zeichen gesetzt dass wir mit einheimischen materialien nachhaltig bauen wollen \n",
            " decoded wombat:  die k da wiree da wimit einhmhe rsuren a noanen \n",
            " decoded beam:   \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  diesen muesste man in zwei kleinen dingen korrigieren \n",
            " decoded wombat:  dam muesst man zwei kleine sachen korigieren e \n",
            " decoded beam:  man zwei kleine sachen korrigieren \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  da muss man sich keine illusionen machen \n",
            " decoded wombat:  d mus man sich kenionene \n",
            " decoded beam:  man ich \n",
            "\n",
            "| ---------------------- Result ----------------- |\n",
            "target:  das alles wird im vorliegenden gesetz nicht gemacht \n",
            " decoded wombat:  daes ales wird im vorliegenden gesez nicht gemacht \n",
            " decoded beam:  da als wir im vorliegenden gesetz nicht gemacht \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w/10."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smvbTfAmZMZG",
        "outputId": "69f2ff1b-e44f-481e-ef62-9c8906e54d58"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6850089126559715"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c/10."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btyh-M83ZPRp",
        "outputId": "0a4274e0-53b2-4442-a640-9ff182113ffd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38864297860348407"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w/20."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9W68noMacth",
        "outputId": "f8f3300f-2af3-42c3-d9d6-f0225a9f2249"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7104410866910867"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c/20."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLn-GR0BafDe",
        "outputId": "bcc42d04-b0f1-40e4-f31f-764172881210"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4919885399580024"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}